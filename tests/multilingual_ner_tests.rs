//! Multilingual NER tests - exposing limitations of pattern and statistical approaches.
//!
//! These tests demonstrate where RegexNER and HeuristicNER fail on non-English text,
//! serving as a baseline for future ML-based improvements.
//!
//! ## Key Findings from Research
//!
//! 1. **RegexNER (regex)**: Works well across languages for structured entities
//!    (dates, emails, URLs, money with $ â‚¬ Â£ Â¥) but fails for:
//!    - Language-specific date formats (Japanese å¹´æœˆæ—¥, Arabic numerals)
//!    - Currency names in other languages
//!
//! 2. **HeuristicNER (heuristics)**: Heavily English-biased because:
//!    - Relies on capitalization (fails for Chinese, Japanese, Arabic, Hebrew)
//!    - Uses English context words ("Mr.", "Inc.", "in New York")
//!    - English first names gazetteer
//!
//! ## Language Categories by Difficulty
//!
//! | Category | Languages | Capitalization | Challenge |
//! |----------|-----------|----------------|-----------|
//! | Easy | German, Spanish, French | Yes (like English) | Different word lists |
//! | Medium | Russian, Greek | Yes (different alphabet) | Script differences |
//! | Hard | Chinese, Japanese | No | No capitalization signal |
//! | Very Hard | Arabic, Hebrew | No + RTL | Script direction + no caps |
//!
//! ## References
//!
//! - WikiANN (PAN-X): 282 languages, PER/LOC/ORG
//! - MultiCoNER: 12 languages, 33 fine-grained types
//! - CoNLL 2002/2003: Spanish, Dutch, German, English

use anno::{Entity, EntityType, HeuristicNER, Model, RegexNER, StackedNER};

// =============================================================================
// Test Helpers
// =============================================================================

fn pattern() -> RegexNER {
    RegexNER::new()
}

fn stats() -> HeuristicNER {
    HeuristicNER::new()
}

fn stacked() -> StackedNER {
    StackedNER::default()
}

fn has_type(entities: &[Entity], ty: EntityType) -> bool {
    entities.iter().any(|e| e.entity_type == ty)
}

fn find_text<'a>(entities: &'a [Entity], text: &str) -> Option<&'a Entity> {
    entities.iter().find(|e| e.text == text)
}

fn entity_texts(entities: &[Entity]) -> Vec<&str> {
    entities.iter().map(|e| e.text.as_str()).collect()
}

// =============================================================================
// PATTERN NER: Language-Agnostic Structured Entities
// =============================================================================

mod pattern_multilingual {
    use super::*;

    // -------------------------------------------------------------------------
    // These SHOULD work across all languages (format-based)
    // -------------------------------------------------------------------------

    #[test]
    fn iso_dates_universal() {
        // ISO 8601 is language-agnostic
        let cases = [
            "ä¼šè®®æ—¥æœŸ 2024-01-15", // Chinese
            "Datum: 2024-01-15",   // German
            "Fecha: 2024-01-15",   // Spanish
            "Ø§Ù„ØªØ§Ø±ÙŠØ® 2024-01-15",  // Arabic
            "æ—¥ä»˜: 2024-01-15",    // Japanese
            "Ğ”Ğ°Ñ‚Ğ°: 2024-01-15",    // Russian
        ];

        for text in cases {
            let e = pattern().extract_entities(text, None).unwrap();
            assert!(
                has_type(&e, EntityType::Date),
                "Should find ISO date in: {}",
                text
            );
        }
    }

    #[test]
    fn emails_universal() {
        // Email format is truly universal
        let cases = [
            "è”ç³»: test@example.com",    // Chinese
            "Kontakt: test@example.com", // German
            "Contato: test@example.com", // Portuguese
            "é€£çµ¡å…ˆ: test@example.com",  // Japanese
            "ĞšĞ¾Ğ½Ñ‚Ğ°ĞºÑ‚: test@example.com", // Russian
            "Ø§Ù„Ø§ØªØµØ§Ù„: test@example.com",  // Arabic
        ];

        for text in cases {
            let e = pattern().extract_entities(text, None).unwrap();
            assert!(
                find_text(&e, "test@example.com").is_some(),
                "Should find email in: {}",
                text
            );
        }
    }

    #[test]
    fn urls_universal() {
        let cases = [
            "è®¿é—® https://example.com",
            "Besuchen Sie https://example.com",
            "ĞŸĞ¾ÑĞµÑ‚Ğ¸Ñ‚Ğµ https://example.com",
            "è¨ªå• https://example.com",
        ];

        for text in cases {
            let e = pattern().extract_entities(text, None).unwrap();
            assert!(
                has_type(&e, EntityType::Url),
                "Should find URL in: {}",
                text
            );
        }
    }

    #[test]
    fn money_with_symbols_universal() {
        // Currency symbols work across contexts
        let cases = [
            ("ä»·æ ¼ $100", "$100"),
            ("Preis: â‚¬500", "â‚¬500"),
            ("Prix: Â£200", "Â£200"),
            ("ä¾¡æ ¼: Â¥10000", "Â¥10000"),
        ];

        for (text, expected) in cases {
            let e = pattern().extract_entities(text, None).unwrap();
            assert!(
                find_text(&e, expected).is_some(),
                "Should find {} in: {}",
                expected,
                text
            );
        }
    }

    // -------------------------------------------------------------------------
    // These FAIL - language-specific date/money formats
    // -------------------------------------------------------------------------

    #[test]
    fn german_date_format() {
        // German uses DD.MM.YYYY (supported)
        let text = "Termin am 15.01.2024";
        let e = pattern().extract_entities(text, None).unwrap();
        // This SHOULD work - we have DATE_EU pattern
        assert!(
            has_type(&e, EntityType::Date),
            "German date format: {:?}",
            e
        );
    }

    #[test]
    fn japanese_date_format_supported() {
        // Japanese å¹´æœˆæ—¥ format - NOW SUPPORTED
        let text = "ä¼šè­°ã¯2024å¹´1æœˆ15æ—¥ã§ã™";
        let e = pattern().extract_entities(text, None).unwrap();
        assert!(
            has_type(&e, EntityType::Date),
            "Japanese date format (å¹´æœˆæ—¥) should be supported: {:?}",
            e
        );
        let date = e
            .iter()
            .find(|e| e.entity_type == EntityType::Date)
            .unwrap();
        assert_eq!(date.text, "2024å¹´1æœˆ15æ—¥");
    }

    #[test]
    fn french_date_written() {
        // "15 janvier 2024" - SHOULD work with DATE_WRITTEN_EU pattern
        let text = "RÃ©union le 15 January 2024"; // Using English month name
        let e = pattern().extract_entities(text, None).unwrap();
        assert!(
            has_type(&e, EntityType::Date),
            "Date with English month: {:?}",
            e
        );
    }

    #[test]
    fn french_month_names_supported() {
        // French month names - NOW SUPPORTED
        let cases = [
            ("RÃ©union le 15 janvier 2024", "15 janvier 2024"),
            ("Le 1er fÃ©vrier", "1er fÃ©vrier"),
            ("Date: 25 dÃ©cembre 2023", "25 dÃ©cembre 2023"),
        ];
        for (text, expected) in cases {
            let e = pattern().extract_entities(text, None).unwrap();
            assert!(
                has_type(&e, EntityType::Date),
                "French month should be supported in: {}",
                text
            );
            let date = e
                .iter()
                .find(|e| e.entity_type == EntityType::Date)
                .unwrap();
            assert_eq!(date.text, expected, "Wrong text for: {}", text);
        }
    }

    #[test]
    fn german_month_names_supported() {
        // German month names - NOW SUPPORTED
        let cases = [
            ("Termin am 15. Januar 2024", "15. Januar 2024"),
            ("Am 3 MÃ¤rz beginnt", "3 MÃ¤rz"),
            ("Der 25 Dezember ist", "25 Dezember"),
        ];
        for (text, expected) in cases {
            let e = pattern().extract_entities(text, None).unwrap();
            assert!(
                has_type(&e, EntityType::Date),
                "German month should be supported in: {}",
                text
            );
            let date = e
                .iter()
                .find(|e| e.entity_type == EntityType::Date)
                .unwrap();
            assert_eq!(date.text, expected, "Wrong text for: {}", text);
        }
    }

    #[test]
    fn spanish_month_names_supported() {
        let cases = [
            ("Fecha: 15 de enero de 2024", "15 de enero de 2024"),
            ("El 5 marzo", "5 marzo"),
        ];
        for (text, expected) in cases {
            let e = pattern().extract_entities(text, None).unwrap();
            assert!(
                has_type(&e, EntityType::Date),
                "Spanish month should be supported in: {}",
                text
            );
            let date = e
                .iter()
                .find(|e| e.entity_type == EntityType::Date)
                .unwrap();
            assert_eq!(date.text, expected, "Wrong text for: {}", text);
        }
    }

    #[test]
    fn italian_month_names_supported() {
        let text = "Data: 15 gennaio 2024";
        let e = pattern().extract_entities(text, None).unwrap();
        assert!(has_type(&e, EntityType::Date), "Italian month: {:?}", e);
    }

    #[test]
    fn portuguese_month_names_supported() {
        let text = "Data: 15 de janeiro de 2024";
        let e = pattern().extract_entities(text, None).unwrap();
        assert!(has_type(&e, EntityType::Date), "Portuguese month: {:?}", e);
    }

    #[test]
    fn dutch_month_names_supported() {
        let text = "Datum: 15 januari 2024";
        let e = pattern().extract_entities(text, None).unwrap();
        assert!(has_type(&e, EntityType::Date), "Dutch month: {:?}", e);
    }

    #[test]
    fn russian_month_names_supported() {
        let text = "Ğ”Ğ°Ñ‚Ğ°: 15 ÑĞ½Ğ²Ğ°Ñ€Ñ 2024";
        let e = pattern().extract_entities(text, None).unwrap();
        assert!(has_type(&e, EntityType::Date), "Russian month: {:?}", e);
    }

    #[test]
    fn korean_date_format_supported() {
        let text = "ë‚ ì§œ: 2024ë…„ 1ì›” 15ì¼";
        let e = pattern().extract_entities(text, None).unwrap();
        assert!(has_type(&e, EntityType::Date), "Korean date: {:?}", e);
    }

    #[test]
    fn arabic_indic_numerals_supported() {
        // Eastern Arabic numerals (Ù Ù¡Ù¢Ù£Ù¤Ù¥Ù¦Ù§Ù¨Ù©)
        // Rust regex has Unicode support by default - \d matches all Unicode digits!
        let text = "Ø§Ù„Ø³Ø¹Ø±: $Ù¡Ù¢Ù£"; // $123 in Arabic-Indic numerals
        let e = pattern().extract_entities(text, None).unwrap();
        // Positive finding: Rust regex \d matches Unicode digits
        assert!(
            has_type(&e, EntityType::Money),
            "Arabic-Indic numerals ARE supported (Rust regex \\d is Unicode-aware): {:?}",
            e
        );
        // Verify the text was captured correctly
        let money = e
            .iter()
            .find(|e| e.entity_type == EntityType::Money)
            .unwrap();
        assert_eq!(money.text, "$Ù¡Ù¢Ù£");
    }

    #[test]
    fn chinese_currency_words_not_supported() {
        // Chinese currency expression without symbol
        let text = "ä»·æ ¼æ˜¯ä¸€ç™¾ç¾å…ƒ"; // "The price is 100 dollars"
        let e = pattern().extract_entities(text, None).unwrap();
        // Documents limitation: no pattern for Chinese currency words
        assert!(
            !has_type(&e, EntityType::Money),
            "Chinese currency words NOT supported (would need NLP): {:?}",
            e
        );
    }
}

// =============================================================================
// STATISTICAL NER: English-Centric Heuristics
// =============================================================================

mod statistical_multilingual {
    use super::*;

    // -------------------------------------------------------------------------
    // Languages WITH capitalization (should partially work)
    // -------------------------------------------------------------------------

    #[test]
    fn german_capitalized_entities() {
        // German capitalizes ALL nouns, not just proper nouns
        // This creates massive false positive problem
        let text = "Der Mann arbeitet bei der Firma in der Stadt.";
        // "The man works at the company in the city."
        // Mann, Firma, Stadt are all capitalized but NOT entities

        let e = stats().extract_entities(text, None).unwrap();

        // Statistical NER will likely find false positives
        // This test documents the problem
        println!("German common nouns (capitalized): {:?}", entity_texts(&e));
        // Don't assert - just document the behavior
    }

    #[test]
    fn german_real_entities() {
        let text = "Angela Merkel arbeitet in Berlin.";
        let e = stats().extract_entities(text, None).unwrap();

        // Should find Angela Merkel (capitalized, looks like name)
        // Should find Berlin (capitalized, after "in")
        println!("German entities: {:?}", entity_texts(&e));

        // May or may not work - context words are English
    }

    #[test]
    fn spanish_entities() {
        // Spanish capitalizes proper nouns like English
        let text = "Pablo GarcÃ­a trabaja en Madrid para TelefÃ³nica.";
        let e = stats().extract_entities(text, None).unwrap();

        println!("Spanish entities: {:?}", entity_texts(&e));
        // May find "Pablo GarcÃ­a" (capitalized sequence)
        // May find "Madrid" (capitalized after something)
        // May find "TelefÃ³nica" (capitalized)
    }

    #[test]
    fn french_entities() {
        let text = "Emmanuel Macron habite Ã  Paris.";
        let e = stats().extract_entities(text, None).unwrap();

        println!("French entities: {:?}", entity_texts(&e));
        // Similar to Spanish - capitalization helps
    }

    // -------------------------------------------------------------------------
    // Languages WITHOUT capitalization (will fail badly)
    // -------------------------------------------------------------------------

    #[test]
    fn chinese_no_capitalization() {
        // Chinese has no capitalization, but heuristic NER uses known entity lists
        let text = "ææ˜åœ¨åŒ—äº¬çš„é˜¿é‡Œå·´å·´å…¬å¸å·¥ä½œ";
        // "Li Ming works at Alibaba Company in Beijing"
        // ææ˜ = Person, åŒ—äº¬ = Location, é˜¿é‡Œå·´å·´ = Organization

        let e = stats().extract_entities(text, None).unwrap();

        // HeuristicNER now matches known entities (é˜¿é‡Œå·´å·´, åŒ—äº¬) from KNOWN_ORGS/KNOWN_LOCS
        // So it will find some entities even without capitalization
        assert!(!e.is_empty(), "Chinese: {:?}", e);
        // Should find at least åŒ—äº¬ (Beijing) and é˜¿é‡Œå·´å·´ (Alibaba) from known lists
        assert!(
            e.iter().any(|ent| ent.text.contains("åŒ—äº¬")),
            "Should find åŒ—äº¬"
        );
        assert!(
            e.iter().any(|ent| ent.text.contains("é˜¿é‡Œå·´å·´")),
            "Should find é˜¿é‡Œå·´å·´"
        );
    }

    #[test]
    fn japanese_no_capitalization() {
        // Japanese also lacks capitalization, but heuristic NER uses known entity lists
        let text = "ç”°ä¸­å¤ªéƒã¯æ±äº¬ã®ã‚½ãƒ‹ãƒ¼ã§åƒã„ã¦ã„ã¾ã™";
        // "Taro Tanaka works at Sony in Tokyo"

        let e = stats().extract_entities(text, None).unwrap();

        // HeuristicNER now matches known entities (æ±äº¬, ã‚½ãƒ‹ãƒ¼) from KNOWN_LOCS/KNOWN_ORGS
        // So it will find some entities even without capitalization
        assert!(!e.is_empty(), "Japanese: {:?}", e);
        // Should find at least æ±äº¬ (Tokyo) and ã‚½ãƒ‹ãƒ¼ (Sony) from known lists
        assert!(
            e.iter().any(|ent| ent.text.contains("æ±äº¬")),
            "Should find æ±äº¬"
        );
        assert!(
            e.iter().any(|ent| ent.text.contains("ã‚½ãƒ‹ãƒ¼")),
            "Should find ã‚½ãƒ‹ãƒ¼"
        );
    }

    #[test]
    fn korean_no_capitalization() {
        let text = "ê¹€ì² ìˆ˜ëŠ” ì„œìš¸ì—ì„œ ì‚¼ì„±ì „ìì— ë‹¤ë‹™ë‹ˆë‹¤";
        // "Kim Cheolsu works at Samsung Electronics in Seoul"

        let e = stats().extract_entities(text, None).unwrap();

        // WILL FAIL
        assert!(e.is_empty(), "Korean: {:?}", e);
    }

    #[test]
    fn arabic_rtl_no_caps() {
        // Arabic: RTL + no capitalization
        let text = "ÙŠØ¹Ù…Ù„ Ø£Ø­Ù…Ø¯ ÙÙŠ Ø§Ù„Ù‚Ø§Ù‡Ø±Ø© Ù„Ø´Ø±ÙƒØ© Ù…Ø§ÙŠÙƒØ±ÙˆØ³ÙˆÙØª";
        // "Ahmed works in Cairo for Microsoft"

        let e = stats().extract_entities(text, None).unwrap();

        // WILL FAIL - no capitalization + RTL complexity
        assert!(e.is_empty(), "Arabic: {:?}", e);
    }

    #[test]
    fn hebrew_rtl_no_caps() {
        let text = "×“×•×“ ×¢×•×‘×“ ×‘×™×¨×•×©×œ×™× ×‘×—×‘×¨×ª ×’×•×’×œ";
        // "David works in Jerusalem at Google company"

        let e = stats().extract_entities(text, None).unwrap();

        assert!(e.is_empty(), "Hebrew: {:?}", e);
    }

    // -------------------------------------------------------------------------
    // Mixed scripts (partial success)
    // -------------------------------------------------------------------------

    #[test]
    fn chinese_with_english_names() {
        // When English names appear in Chinese text, capitalization helps
        let text = "Steve Jobsåˆ›ç«‹äº†Appleå…¬å¸";
        // "Steve Jobs founded Apple company"

        let e = stats().extract_entities(text, None).unwrap();

        // Might find "Steve Jobs" and "Apple" due to capitalization
        println!("Chinese+English: {:?}", entity_texts(&e));

        // The English parts might be detected
        let found_steve = e.iter().any(|e| e.text.contains("Steve"));
        let found_apple = e.iter().any(|e| e.text.contains("Apple"));

        if found_steve || found_apple {
            println!("Partial success: English names detected in Chinese text");
        }
    }

    #[test]
    fn japanese_with_katakana() {
        // Katakana often used for foreign names - provides some signal
        let text = "ãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆã®ãƒ“ãƒ«ãƒ»ã‚²ã‚¤ãƒ„æ°";
        // "Microsoft's Bill Gates"

        let e = stats().extract_entities(text, None).unwrap();

        // Katakana doesn't help our English-based heuristics
        println!("Japanese katakana: {:?}", entity_texts(&e));
    }
}

// =============================================================================
// STACKED NER: Combined Behavior
// =============================================================================

mod stacked_multilingual {
    use super::*;

    #[test]
    fn stacked_chinese_partial() {
        // Pattern layer finds structured entities
        // Statistical layer finds nothing (no caps)
        let text = "ä¼šè®®æ—¥æœŸ 2024-01-15ï¼Œè”ç³» test@example.comï¼Œè´¹ç”¨ $100";

        let e = stacked().extract_entities(text, None).unwrap();

        // Pattern should find: date, email, money
        assert!(has_type(&e, EntityType::Date), "Should find date");
        assert!(has_type(&e, EntityType::Email), "Should find email");
        assert!(has_type(&e, EntityType::Money), "Should find money");

        // But NO named entities (Person, Org, Location)
        assert!(!has_type(&e, EntityType::Person), "Should NOT find person");
        assert!(
            !has_type(&e, EntityType::Organization),
            "Should NOT find org"
        );
        assert!(
            !has_type(&e, EntityType::Location),
            "Should NOT find location"
        );
    }

    #[test]
    fn stacked_german_mixed() {
        let text = "Angela Merkel besucht Berlin am 2024-01-15. Kontakt: merkel@gov.de";

        let e = stacked().extract_entities(text, None).unwrap();

        // Pattern: date, email
        assert!(has_type(&e, EntityType::Date), "Should find date");
        assert!(has_type(&e, EntityType::Email), "Should find email");

        // Statistical: might find Angela Merkel, Berlin
        // (capitalized, though context words won't match perfectly)
        println!("German stacked: {:?}", entity_texts(&e));
    }
}

// =============================================================================
// POTENTIAL IMPROVEMENTS (documented as tests)
// =============================================================================

mod improvement_opportunities {
    #![allow(unused_imports)]
    use super::*;

    /// Japanese date pattern: YYYYå¹´MMæœˆDDæ—¥
    /// Adding this would be straightforward:
    /// ```regex
    /// (\d{4})å¹´(\d{1,2})æœˆ(\d{1,2})æ—¥
    /// ```
    #[test]
    fn document_japanese_date_pattern() {
        let text = "2024å¹´1æœˆ15æ—¥";
        let pattern = r"(\d{4})å¹´(\d{1,2})æœˆ(\d{1,2})æ—¥";
        let re = regex::Regex::new(pattern).unwrap();
        assert!(re.is_match(text), "Japanese date pattern works");
    }

    /// Multilingual month names
    /// Could extend DATE_WRITTEN patterns with:
    /// - German: Januar, Februar, MÃ¤rz, April, Mai, Juni, Juli, August, September, Oktober, November, Dezember
    /// - French: janvier, fÃ©vrier, mars, avril, mai, juin, juillet, aoÃ»t, septembre, octobre, novembre, dÃ©cembre
    /// - Spanish: enero, febrero, marzo, abril, mayo, junio, julio, agosto, septiembre, octubre, noviembre, diciembre
    #[test]
    fn document_multilingual_months() {
        let months_de = [
            "Januar",
            "Februar",
            "MÃ¤rz",
            "April",
            "Mai",
            "Juni",
            "Juli",
            "August",
            "September",
            "Oktober",
            "November",
            "Dezember",
        ];
        let months_fr = [
            "janvier",
            "fÃ©vrier",
            "mars",
            "avril",
            "mai",
            "juin",
            "juillet",
            "aoÃ»t",
            "septembre",
            "octobre",
            "novembre",
            "dÃ©cembre",
        ];
        let months_es = [
            "enero",
            "febrero",
            "marzo",
            "abril",
            "mayo",
            "junio",
            "julio",
            "agosto",
            "septiembre",
            "octubre",
            "noviembre",
            "diciembre",
        ];

        // All defined - would need to be added to pattern.rs
        assert_eq!(months_de.len(), 12);
        assert_eq!(months_fr.len(), 12);
        assert_eq!(months_es.len(), 12);
    }

    /// Unicode-aware digit matching in Rust regex
    ///
    /// POSITIVE FINDING: Rust regex crate has Unicode support enabled by default!
    /// The `\d` character class matches all Unicode decimal digits, including:
    /// - ASCII: 0-9
    /// - Arabic-Indic: Ù -Ù©
    /// - Extended Arabic-Indic (Persian): Û°-Û¹
    /// - And many more Unicode digit characters
    #[test]
    fn document_unicode_digits_supported() {
        let text = "Ù¡Ù¢Ù£"; // 123 in Arabic-Indic

        // Rust regex \d matches Unicode digits by default
        let re = regex::Regex::new(r"\d+").unwrap();
        let matches = re.is_match(text);

        // This is a POSITIVE finding - Unicode digits work out of the box
        assert!(
            matches,
            "Rust regex \\d DOES match Arabic-Indic numerals (Unicode support is default)"
        );

        // Verify we can extract the match
        let m = re.find(text).unwrap();
        assert_eq!(m.as_str(), "Ù¡Ù¢Ù£");

        // This means RegexNER works with Arabic-Indic numerals automatically!
    }

    /// For non-capitalizing languages, could use:
    /// 1. Script detection (Chinese characters = CJK block)
    /// 2. Character n-gram features
    /// 3. Dictionary-based lookup (gazetteers)
    /// 4. ML backends (GLiNER, NuNER)
    #[test]
    fn document_cjk_approaches() {
        // Unicode script detection
        let chinese = 'ä¸­';
        let japanese_hiragana = 'ã‚';
        let japanese_katakana = 'ã‚¢';
        let _korean = 'í•œ';

        // Could use Unicode blocks to detect script
        // CJK Unified Ideographs: U+4E00..U+9FFF
        let is_cjk = |c: char| matches!(c as u32, 0x4E00..=0x9FFF);

        assert!(is_cjk(chinese));
        // Hiragana/Katakana are different blocks
        assert!(!is_cjk(japanese_hiragana));
        assert!(!is_cjk(japanese_katakana));
    }
}

// =============================================================================
// BENCHMARK: Expected Performance by Language
// =============================================================================

/// Summary of expected performance by language and backend.
///
/// | Language | RegexNER | HeuristicNER | Notes |
/// |----------|------------|----------------|-------|
/// | English | High | Medium | Reference implementation |
/// | German | High | Low-Medium | All nouns capitalized (FP problem) |
/// | French | High | Medium | Caps work, need FR months |
/// | Spanish | High | Medium | Similar to French |
/// | Russian | Medium | Low | Cyrillic script, caps work |
/// | Chinese | Medium | None | No caps, need ML/gazetteers |
/// | Japanese | Low | None | No caps, multiple scripts |
/// | Arabic | Low | None | RTL, no caps, different numerals |
/// | Korean | Medium | None | No caps, need ML |
///
/// For production multilingual NER, use:
/// - GLiNER/NuNER for named entities (zero-shot works across languages)
/// - RegexNER for structured entities (extend date patterns)
#[test]
fn performance_expectations_documented() {
    // This test exists to document expected behavior
    // See table above in doc comment

    // RegexNER: ~95%+ precision on supported patterns, any language
    // HeuristicNER: ~60-70% F1 English, near-zero for CJK/Arabic

    assert!(true, "Documentation test");
}

// =============================================================================
// REGRESSION: Unicode Offset Handling
// =============================================================================

mod unicode_offsets {
    use super::*;

    #[test]
    fn chinese_text_offsets_valid() {
        let text = "ä»·æ ¼æ˜¯ $100 ç¾å…ƒ";
        let e = pattern().extract_entities(text, None).unwrap();

        for entity in &e {
            // Offsets should be character offsets, not byte offsets
            let char_count = text.chars().count();
            assert!(
                entity.start <= char_count,
                "Start {} > char count {}",
                entity.start,
                char_count
            );
            assert!(
                entity.end <= char_count,
                "End {} > char count {}",
                entity.end,
                char_count
            );

            // Extract by char offset should match text
            let extracted: String = text
                .chars()
                .skip(entity.start)
                .take(entity.end - entity.start)
                .collect();
            assert_eq!(extracted, entity.text, "Offset mismatch");
        }
    }

    #[test]
    fn emoji_text_offsets_valid() {
        let text = "ğŸ“§ Email: test@example.com ğŸ‰";
        let e = pattern().extract_entities(text, None).unwrap();

        let email = find_text(&e, "test@example.com").expect("Should find email");

        // Verify extraction by offset works
        let extracted: String = text
            .chars()
            .skip(email.start)
            .take(email.end - email.start)
            .collect();
        assert_eq!(extracted, "test@example.com");
    }

    #[test]
    fn mixed_script_offsets_valid() {
        // Mix of ASCII, CJK, emoji
        let text = "æ—¥æœŸ: 2024-01-15 ğŸ“… è´¹ç”¨: $100";
        let e = pattern().extract_entities(text, None).unwrap();

        for entity in &e {
            let extracted: String = text
                .chars()
                .skip(entity.start)
                .take(entity.end - entity.start)
                .collect();
            assert_eq!(extracted, entity.text, "Offset mismatch for {:?}", entity);
        }
    }
}
